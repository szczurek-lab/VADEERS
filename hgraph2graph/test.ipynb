{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hgraph.mol_graph import MolGraph\n",
    "from hgraph.encoder import HierMPNEncoder\n",
    "from hgraph.decoder import HierMPNDecoder\n",
    "from hgraph.vocab import Vocab, PairVocab, common_atom_vocab\n",
    "from hgraph.hgnn import HierVAE, HierVGNN, HierCondVGNN\n",
    "from hgraph.dataset import MoleculeDataset, MolPairDataset, DataFolder, MolEnumRootDataset\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Foo')\n",
    "\n",
    "parser.add_argument('--train', default='train_processed/')\n",
    "parser.add_argument('--vocab', default='data/chembl/vocab.txt')\n",
    "parser.add_argument('--atom_vocab', default=common_atom_vocab)\n",
    "parser.add_argument('--save_dir', default='ckpt/chembl-pretrained')\n",
    "parser.add_argument('--model', default='ckpt/chembl-pretrained/model.ckpt')\n",
    "parser.add_argument('--seed', type=int, default=7)\n",
    "\n",
    "parser.add_argument('--rnn_type', type=str, default='LSTM')\n",
    "parser.add_argument('--hidden_size', type=int, default=250)\n",
    "parser.add_argument('--embed_size', type=int, default=250)\n",
    "parser.add_argument('--batch_size', type=int, default=50)\n",
    "parser.add_argument('--latent_size', type=int, default=32)\n",
    "parser.add_argument('--depthT', type=int, default=15)\n",
    "parser.add_argument('--depthG', type=int, default=15)\n",
    "parser.add_argument('--diterT', type=int, default=1)\n",
    "parser.add_argument('--diterG', type=int, default=3)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "parser.add_argument('--epoch', type=int, default=20)\n",
    "parser.add_argument('--anneal_rate', type=float, default=0.9)\n",
    "parser.add_argument('--anneal_iter', type=int, default=25000)\n",
    "parser.add_argument('--print_iter', type=int, default=50)\n",
    "parser.add_argument('--save_iter', type=int, default=5000)\n",
    "\n",
    "parser.add_argument('--nsample', type=int, default=100)\n",
    "\n",
    "parser.add_argument('--ncpu', type=int, default=8)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(args.vocab)]\n",
    "args.vocab = PairVocab(vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": "HierVAE(\n  (encoder): HierMPNEncoder(\n    (E_c): Sequential(\n      (0): Embedding(1578, 250)\n      (1): Dropout(p=0.0, inplace=False)\n    )\n    (E_i): Sequential(\n      (0): Embedding(5623, 250)\n      (1): Dropout(p=0.0, inplace=False)\n    )\n    (W_c): Sequential(\n      (0): Linear(in_features=500, out_features=250, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.0, inplace=False)\n    )\n    (W_i): Sequential(\n      (0): Linear(in_features=500, out_features=250, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.0, inplace=False)\n    )\n    (W_root): Sequential(\n      (0): Linear(in_features=500, out_features=250, bias=True)\n      (1): Tanh()\n    )\n    (tree_encoder): MPNEncoder(\n      (W_o): Sequential(\n        (0): Linear(in_features=500, out_features=250, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.0, inplace=False)\n      )\n      (rnn): LSTM(\n        (W_i): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W_o): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W_f): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Tanh()\n        )\n      )\n    )\n    (inter_encoder): MPNEncoder(\n      (W_o): Sequential(\n        (0): Linear(in_features=500, out_features=250, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.0, inplace=False)\n      )\n      (rnn): LSTM(\n        (W_i): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W_o): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W_f): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W): Sequential(\n          (0): Linear(in_features=520, out_features=250, bias=True)\n          (1): Tanh()\n        )\n      )\n    )\n    (graph_encoder): MPNEncoder(\n      (W_o): Sequential(\n        (0): Linear(in_features=288, out_features=250, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.0, inplace=False)\n      )\n      (rnn): LSTM(\n        (W_i): Sequential(\n          (0): Linear(in_features=312, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W_o): Sequential(\n          (0): Linear(in_features=312, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W_f): Sequential(\n          (0): Linear(in_features=312, out_features=250, bias=True)\n          (1): Sigmoid()\n        )\n        (W): Sequential(\n          (0): Linear(in_features=312, out_features=250, bias=True)\n          (1): Tanh()\n        )\n      )\n    )\n  )\n  (decoder): HierMPNDecoder(\n    (hmpn): IncHierMPNEncoder(\n      (E_c): Sequential(\n        (0): Embedding(1578, 250)\n        (1): Dropout(p=0.0, inplace=False)\n      )\n      (E_i): Sequential(\n        (0): Embedding(5623, 250)\n        (1): Dropout(p=0.0, inplace=False)\n      )\n      (W_c): Sequential(\n        (0): Linear(in_features=500, out_features=250, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.0, inplace=False)\n      )\n      (W_i): Sequential(\n        (0): Linear(in_features=500, out_features=250, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.0, inplace=False)\n      )\n      (tree_encoder): IncMPNEncoder(\n        (W_o): Sequential(\n          (0): Linear(in_features=500, out_features=250, bias=True)\n          (1): ReLU()\n          (2): Dropout(p=0.0, inplace=False)\n        )\n        (rnn): LSTM(\n          (W_i): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W_o): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W_f): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Tanh()\n          )\n        )\n      )\n      (inter_encoder): IncMPNEncoder(\n        (W_o): Sequential(\n          (0): Linear(in_features=500, out_features=250, bias=True)\n          (1): ReLU()\n          (2): Dropout(p=0.0, inplace=False)\n        )\n        (rnn): LSTM(\n          (W_i): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W_o): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W_f): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W): Sequential(\n            (0): Linear(in_features=520, out_features=250, bias=True)\n            (1): Tanh()\n          )\n        )\n      )\n      (graph_encoder): IncMPNEncoder(\n        (W_o): Sequential(\n          (0): Linear(in_features=288, out_features=250, bias=True)\n          (1): ReLU()\n          (2): Dropout(p=0.0, inplace=False)\n        )\n        (rnn): LSTM(\n          (W_i): Sequential(\n            (0): Linear(in_features=312, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W_o): Sequential(\n            (0): Linear(in_features=312, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W_f): Sequential(\n            (0): Linear(in_features=312, out_features=250, bias=True)\n            (1): Sigmoid()\n          )\n          (W): Sequential(\n            (0): Linear(in_features=312, out_features=250, bias=True)\n            (1): Tanh()\n          )\n        )\n      )\n    )\n    (rnn_cell): LSTM(\n      (W_i): Sequential(\n        (0): Linear(in_features=520, out_features=250, bias=True)\n        (1): Sigmoid()\n      )\n      (W_o): Sequential(\n        (0): Linear(in_features=520, out_features=250, bias=True)\n        (1): Sigmoid()\n      )\n      (W_f): Sequential(\n        (0): Linear(in_features=520, out_features=250, bias=True)\n        (1): Sigmoid()\n      )\n      (W): Sequential(\n        (0): Linear(in_features=520, out_features=250, bias=True)\n        (1): Tanh()\n      )\n    )\n    (E_assm): Sequential(\n      (0): Embedding(5623, 250)\n      (1): Dropout(p=0.0, inplace=False)\n    )\n    (topoNN): Sequential(\n      (0): Linear(in_features=282, out_features=250, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.0, inplace=False)\n      (3): Linear(in_features=250, out_features=1, bias=True)\n    )\n    (clsNN): Sequential(\n      (0): Linear(in_features=282, out_features=250, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.0, inplace=False)\n      (3): Linear(in_features=250, out_features=1578, bias=True)\n    )\n    (iclsNN): Sequential(\n      (0): Linear(in_features=282, out_features=250, bias=True)\n      (1): ReLU()\n      (2): Dropout(p=0.0, inplace=False)\n      (3): Linear(in_features=250, out_features=5623, bias=True)\n    )\n    (matchNN): Sequential(\n      (0): Linear(in_features=520, out_features=250, bias=True)\n      (1): ReLU()\n    )\n    (W_assm): Linear(in_features=250, out_features=32, bias=True)\n    (W_root): Linear(in_features=32, out_features=250, bias=True)\n    (topo_loss): BCEWithLogitsLoss()\n    (cls_loss): CrossEntropyLoss()\n    (icls_loss): CrossEntropyLoss()\n    (assm_loss): CrossEntropyLoss()\n  )\n  (R_mean): Linear(in_features=250, out_features=32, bias=True)\n  (R_var): Linear(in_features=250, out_features=32, bias=True)\n)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HierVAE(args)\n",
    "\n",
    "model_state, optimizer_state, total_step, beta = torch.load(args.model)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(args.nsample // args.batch_size)):\n",
    "        smiles_list = model.sample(args.batch_size, greedy=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'graph_tensors'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmiles_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "\u001B[0;31mTypeError\u001B[0m: forward() missing 1 required positional argument: 'graph_tensors'"
     ]
    }
   ],
   "source": [
    "model.encoder(smiles_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/home/adam/Projects/hgraph2graph/data/chembl/all.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotADirectoryError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [8], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m args\u001B[38;5;241m.\u001B[39mtrain \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/home/adam/Projects/hgraph2graph/data/chembl/all.txt\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mDataFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(dataset):\n\u001B[1;32m      7\u001B[0m     total_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/dataset.py:90\u001B[0m, in \u001B[0;36mDataFolder.__init__\u001B[0;34m(self, data_folder, batch_size, shuffle)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_folder, batch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_folder \u001B[38;5;241m=\u001B[39m data_folder\n\u001B[0;32m---> 90\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_files \u001B[38;5;241m=\u001B[39m [fn \u001B[38;5;28;01mfor\u001B[39;00m fn \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_folder\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size \u001B[38;5;241m=\u001B[39m batch_size\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshuffle \u001B[38;5;241m=\u001B[39m shuffle\n",
      "\u001B[0;31mNotADirectoryError\u001B[0m: [Errno 20] Not a directory: '/home/adam/Projects/hgraph2graph/data/chembl/all.txt'"
     ]
    }
   ],
   "source": [
    "args.train = '/home/adam/Projects/hgraph2graph/data/chembl/all.txt'\n",
    "\n",
    "\n",
    "dataset = DataFolder(args.train, args.batch_size)\n",
    "\n",
    "for batch in tqdm(dataset):\n",
    "    total_step += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "with open(args.vocab) as f:\n",
    "    vocab = [x.strip(\"\\r\\n \").split() for x in f]\n",
    "args.vocab = PairVocab(vocab, cuda=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def tensorize(mol_batch, vocab):\n",
    "    x = MolGraph.tensorize(mol_batch, vocab, common_atom_vocab)\n",
    "    return to_numpy(x)\n",
    "\n",
    "def to_numpy(tensors):\n",
    "    convert = lambda x : x.numpy() if type(x) is torch.Tensor else x\n",
    "    a,b,c = tensors\n",
    "    b = [convert(x) for x in b[0]], [convert(x) for x in b[1]]\n",
    "    return a, b, c"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRemoteTraceback\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;31mRemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/adam/miniconda3/envs/hgraph2graph/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/adam/miniconda3/envs/hgraph2graph/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\nTypeError: 'tuple' object is not callable\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [54], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m batches \u001B[38;5;241m=\u001B[39m [smiles_list[i : i \u001B[38;5;241m+\u001B[39m args\u001B[38;5;241m.\u001B[39mbatch_size] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(smiles_list), args\u001B[38;5;241m.\u001B[39mbatch_size)]\n\u001B[1;32m      4\u001B[0m func \u001B[38;5;241m=\u001B[39m tensorize(mol_batch\u001B[38;5;241m=\u001B[39msmiles_list, vocab\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mvocab)\n\u001B[0;32m----> 5\u001B[0m all_data \u001B[38;5;241m=\u001B[39m \u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatches\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m num_splits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlen\u001B[39m(all_data) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      8\u001B[0m le \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlen\u001B[39m(all_data) \u001B[38;5;241m+\u001B[39m num_splits \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_splits\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/multiprocessing/pool.py:364\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    360\u001B[0m     \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 364\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/multiprocessing/pool.py:771\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n\u001B[1;32m    770\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 771\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "\u001B[0;31mTypeError\u001B[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "pool = Pool(args.ncpu)\n",
    "\n",
    "batches = [smiles_list[i : i + args.batch_size] for i in range(0, len(smiles_list), args.batch_size)]\n",
    "func = tensorize(mol_batch=smiles_list, vocab=args.vocab)\n",
    "all_data = pool.map(func, batches[0])\n",
    "num_splits = max(len(all_data) // 1000, 1)\n",
    "\n",
    "le = (len(all_data) + num_splits - 1) // num_splits\n",
    "\n",
    "for split_id in range(num_splits):\n",
    "    st = split_id * le\n",
    "    sub_data = all_data[st : st + le]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(<networkx.classes.digraph.DiGraph at 0x7fe64a3c9370>,\n <networkx.classes.digraph.DiGraph at 0x7fe64413da00>)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<hgraph.mol_graph.MolGraph at 0x7fe649e4b880>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MolGraph(smiles_list[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "mol_batch = smiles_list\n",
    "mol_batch = [MolGraph(x) for x in mol_batch]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tree_tensors, tree_batchG \u001B[38;5;241m=\u001B[39m \u001B[43mMolGraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensorize_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmol_tree\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmol_batch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/mol_graph.py:194\u001B[0m, in \u001B[0;36mMolGraph.tensorize_graph\u001B[0;34m(graph_batch, vocab)\u001B[0m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m v, attr \u001B[38;5;129;01min\u001B[39;00m G\u001B[38;5;241m.\u001B[39mnodes(data\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    193\u001B[0m     G\u001B[38;5;241m.\u001B[39mnodes[v][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m bid\n\u001B[0;32m--> 194\u001B[0m     fnode[v] \u001B[38;5;241m=\u001B[39m \u001B[43mvocab\u001B[49m\u001B[43m[\u001B[49m\u001B[43mattr\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    195\u001B[0m     agraph\u001B[38;5;241m.\u001B[39mappend([])\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m u, v, attr \u001B[38;5;129;01min\u001B[39;00m G\u001B[38;5;241m.\u001B[39medges(data\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "tree_tensors, tree_batchG = MolGraph.tensorize_graph([x.mol_tree for x in mol_batch], vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DiGraph' object has no attribute 'G'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmol_batch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmol_tree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mG\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DiGraph' object has no attribute 'G'"
     ]
    }
   ],
   "source": [
    "mol_batch[0].mol_tree.G"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<hgraph.vocab.PairVocab at 0x7fe7266de130>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph_tensors, graph_batchG = MolGraph.tensorize_graph([x.mol_graph for x in mol_batch], avocab)\n",
    "tree_scope = tree_tensors[-1]\n",
    "graph_scope = graph_tensors[-1]\n",
    "\n",
    "max_cls_size = max( [len(c) for x in mol_batch for c in x.clusters] )\n",
    "cgraph = torch.zeros(len(tree_batchG) + 1, max_cls_size).int()\n",
    "for v,attr in tree_batchG.nodes(data=True):\n",
    "    bid = attr['batch_id']\n",
    "    offset = graph_scope[bid][0]\n",
    "    tree_batchG.nodes[v]['inter_label'] = inter_label = [(x + offset, y) for x,y in attr['inter_label']]\n",
    "    tree_batchG.nodes[v]['cluster'] = cls = [x + offset for x in attr['cluster']]\n",
    "    tree_batchG.nodes[v]['assm_cands'] = [add(x, offset) for x in attr['assm_cands']]\n",
    "    cgraph[v, :len(cls)] = torch.IntTensor(cls)\n",
    "\n",
    "all_orders = []\n",
    "for i,hmol in enumerate(mol_batch):\n",
    "    offset = tree_scope[i][0]\n",
    "    order = [(x + offset, y + offset, z) for x,y,z in hmol.order[:-1]] + [(hmol.order[-1][0] + offset, None, 0)]\n",
    "    all_orders.append(order)\n",
    "\n",
    "tree_tensors = tree_tensors[:4] + (cgraph, tree_scope)\n",
    "return (tree_batchG, graph_batchG), (tree_tensors, graph_tensors), all_orders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'vocab', 'avocab', and 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mMoleculeDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmiles_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 3 required positional arguments: 'vocab', 'avocab', and 'batch_size'"
     ]
    }
   ],
   "source": [
    "MoleculeDataset(smiles_list, vocab, )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "['Cc1c(Nc2ccnc(N3CC4CC3CN4)n2)sc2ccc(F)cc12',\n 'CCOC(=O)C(=NCCc1ccccc1)SCc1ccccc1',\n 'CC(=O)OCCCCCC(C)(C)CO',\n 'O=C(CC(O)c1ccccc1F)NC1CCCC1',\n 'O=C(CNC(=O)C(Cc1ccc(O)cc1)NCP(=O)(O)O)NO',\n 'CC(=O)N(C(=O)Nc1cc(-c2ccccc2)on1)C1CCCCC1',\n 'O=C(NCCCl)c1ccccc1',\n 'O=[N+]([O-])c1ccc(N=Nc2cccc(Cl)c2)cc1',\n 'CCN(CC)C(=O)CCNC(=O)c1ccco1',\n 'NC(CC(=O)O)C(=O)O',\n 'NC(=O)C(Cc1ccccc1)CC(NC(=O)Cn1c(-c2ccccc2)nc2ccccc21)C(=O)NCc1ccccc1',\n 'O=C(Cc1cccs1)OC1CCCC(F)(F)C1',\n 'CCOC(=O)CSc1cc(Cl)c(Cl)cc1Cl',\n 'COc1ccc(C#Cc2ccccc2F)cc1',\n 'S=C(NCc1ccco1)n1ccnc1',\n 'CN(C)CN1CCN=C1S',\n 'CCOc1ccc(NC(=O)CCn2nnnc2C)cc1',\n 'C=CC[n+]1c(C)cccc1C',\n 'CSc1ccc(NC(=S)N2CCc3ccccc3C2)cc1',\n 'CCC(CC)N(C(=O)COc1ccc(Cl)cc1)C1CCN(C(=O)c2ccccc2Cl)CC1',\n 'O=C(Cc1ccccc1Cl)N1CC(Cc2ccccc2)CC1=O',\n 'Cc1c(CCCSc2ccccc2)cccc1-c1nc2ccccc2o1',\n 'Cc1cnc(-c2cnc(N3CCOCC3)c(C#N)c2)n1-c1ccc(F)cc1',\n 'O=C(CCC(F)(F)F)c1ccccc1',\n 'CCOC(=O)c1ccc2oc(-c3ccccc3)cc(=O)c2c1OCCc1cccc(OCC(=O)O)c1',\n 'Cc1nn(C)c(C)c1Cn1ncc(N2CCC(Oc3ccccc3)CC2)c(Cl)c1=O',\n 'CC(C)(C)NC(=O)NCCO',\n 'COc1ccccc1S(=O)(=O)N1CCN(C(=O)CC(F)(F)F)CC1CN1CCOCC1',\n 'CC(C)NC(=O)c1ccc2ccccc2c1[N+](=O)[O-]',\n 'COc1cc(NC(=O)Cc2ccc(F)cc2)cc([N+](=O)[O-])c1',\n 'NCCCc1ccccn1',\n 'Cc1ccccc1C(NC1CCCC1)c1nccn1C',\n 'COc1ccc(CCn2nc(-c3cccc(NS(C)(=O)=O)c3)c3c(N)nc(C)nc32)cc1',\n 'O=C(O)CCSC(=O)COc1ccccc1',\n 'CCOc1ccccc1N1C(=O)c2ccccc2C1C(=O)O',\n 'O=C(NN=Cc1ccccc1)c1cccc(Cl)c1',\n 'CN(C)c1cccc(NC(=S)Nc2ccccc2)c1',\n 'CCCCNC(=O)CCc1ccccn1',\n 'CC(C)C1CC(NC(=O)N2CCCC2c2nc3ccccc3[nH]2)C2OCCCC2O1',\n 'CCOC(=O)CN1C(=O)CCN(C(=O)CC2CCCC2)CC(OC)c2ccccc21',\n 'COc1cc(C=C(C#N)C(=O)NCCCn2ccnc2)ccc1O',\n 'O=C(Nc1cccc(NS(=O)(=O)c2c(F)cc(F)c(F)c2F)c1)c1ccccc1',\n 'CNC(=O)CCC(=O)NCCC(c1ccccc1)c1ccc(F)cc1',\n 'CNC(=S)Nc1cccc(Oc2ccccc2Cl)c1',\n 'C=CC(C)=CCc1ccccc1OCc1cn(-c2ccc(F)cc2)nn1',\n 'CCOc1ccccc1NC(=O)c1ccccc1NC(C)=O',\n 'CCCc1ccc(-c2ccc(OC)nc2C#Cc2c(C)nc(N)nc2C)cc1',\n 'CCCCCCCCCCCC(=O)NC(C)c1ccccc1',\n 'O=C(O)c1ccccc1N1CCc2ccccc2C1',\n 'CCN(CC)C(=O)Nc1ccccc1[N+](=O)[O-]']"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.83 GiB total capacity; 901.54 MiB already allocated; 19.81 MiB free; 930.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [78], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m dataset \u001B[38;5;241m=\u001B[39m DataFolder(args\u001B[38;5;241m.\u001B[39mtrain, args\u001B[38;5;241m.\u001B[39mbatch_size)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(dataset):\n\u001B[0;32m----> 5\u001B[0m     loss, kl_div, wacc, iacc, tacc, sacc \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/hgnn.py:55\u001B[0m, in \u001B[0;36mHierVAE.forward\u001B[0;34m(self, graphs, tensors, orders, beta, perturb_z)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, graphs, tensors, orders, beta, perturb_z\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     53\u001B[0m     tree_tensors, graph_tensors \u001B[38;5;241m=\u001B[39m tensors \u001B[38;5;241m=\u001B[39m make_cuda(tensors)\n\u001B[0;32m---> 55\u001B[0m     root_vecs, tree_vecs, _, graph_vecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtree_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgraph_tensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     root_vecs, root_kl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrsample(root_vecs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mR_mean, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mR_var, perturb_z)\n\u001B[1;32m     57\u001B[0m     kl_div \u001B[38;5;241m=\u001B[39m root_kl\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/encoder.py:133\u001B[0m, in \u001B[0;36mHierMPNEncoder.forward\u001B[0;34m(self, tree_tensors, graph_tensors)\u001B[0m\n\u001B[1;32m    130\u001B[0m hatom,_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgraph_encoder(\u001B[38;5;241m*\u001B[39mtensors)\n\u001B[1;32m    132\u001B[0m tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_inter(tree_tensors, hatom)\n\u001B[0;32m--> 133\u001B[0m hinter,_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minter_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tree(tree_tensors, hinter)\n\u001B[1;32m    136\u001B[0m hnode,hmess \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtree_encoder(\u001B[38;5;241m*\u001B[39mtensors)\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/encoder.py:30\u001B[0m, in \u001B[0;36mMPNEncoder.forward\u001B[0;34m(self, fnode, fmess, agraph, bgraph)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, fnode, fmess, agraph, bgraph):\n\u001B[0;32m---> 30\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfmess\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbgraph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrnn\u001B[38;5;241m.\u001B[39mget_hidden_state(h)\n\u001B[1;32m     32\u001B[0m     nei_message \u001B[38;5;241m=\u001B[39m index_select_ND(h, \u001B[38;5;241m0\u001B[39m, agraph)\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/rnn.py:105\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, fmess, bgraph)\u001B[0m\n\u001B[1;32m    103\u001B[0m h_nei \u001B[38;5;241m=\u001B[39m index_select_ND(h, \u001B[38;5;241m0\u001B[39m, bgraph)\n\u001B[1;32m    104\u001B[0m c_nei \u001B[38;5;241m=\u001B[39m index_select_ND(c, \u001B[38;5;241m0\u001B[39m, bgraph)\n\u001B[0;32m--> 105\u001B[0m h,c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfmess\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_nei\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_nei\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m h \u001B[38;5;241m=\u001B[39m h \u001B[38;5;241m*\u001B[39m mask\n\u001B[1;32m    107\u001B[0m c \u001B[38;5;241m=\u001B[39m c \u001B[38;5;241m*\u001B[39m mask\n",
      "File \u001B[0;32m~/Projects/hgraph2graph/hgraph/rnn.py:90\u001B[0m, in \u001B[0;36mLSTM.LSTM\u001B[0;34m(self, x, h_nei, c_nei)\u001B[0m\n\u001B[1;32m     88\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_i( torch\u001B[38;5;241m.\u001B[39mcat([x, h_sum_nei], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) )\n\u001B[1;32m     89\u001B[0m o \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_o( torch\u001B[38;5;241m.\u001B[39mcat([x, h_sum_nei], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) )\n\u001B[0;32m---> 90\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_f( \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx_expand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh_nei\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m )\n\u001B[1;32m     91\u001B[0m u \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW( torch\u001B[38;5;241m.\u001B[39mcat([x, h_sum_nei], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) )\n\u001B[1;32m     92\u001B[0m c \u001B[38;5;241m=\u001B[39m i \u001B[38;5;241m*\u001B[39m u \u001B[38;5;241m+\u001B[39m (f \u001B[38;5;241m*\u001B[39m c_nei)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.83 GiB total capacity; 901.54 MiB already allocated; 19.81 MiB free; 930.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    dataset = DataFolder(args.train, args.batch_size)\n",
    "\n",
    "    for batch in tqdm(dataset):\n",
    "        loss, kl_div, wacc, iacc, tacc, sacc = model(*batch, beta=beta)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
