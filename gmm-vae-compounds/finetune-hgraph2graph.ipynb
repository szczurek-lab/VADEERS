{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook performs a finetuning of hgraph2graph model on new data.\n",
    "\n",
    "To run the notebook:\n",
    "1. Extract SMILES from sensitivity table using `gmm-vae-compounds/utils/utils.sensitivity_table_to_smiles_representation` and\n",
    "    save it to `gmm-vae-compounds/models/hgraph2graph/data/vadeers`.\n",
    "2. Supply `gmm-vae-compounds/models/hgraph2graph/data/vadeers` with a vocabulary.\n",
    "\n",
    "Note that in this notebook hyperparameters were changed to fit into GPU's memory.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/adam/Projects/vadeers/code/gmm-vae-compounds/models/hgraph2graph/')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import models.hgraph2graph.hgraph\n",
    "from models.hgraph2graph.hgraph import HierVAE, common_atom_vocab, PairVocab\n",
    "#from chemprop.train import predict\n",
    "##from models.hgraph2graph.hgraph.chemprop.data import MoleculeDataset, MoleculeDataLoader\n",
    "#from models.hgraph2graph.hgraph.chemprop.data.utils import get_data, get_data_from_smiles\n",
    "#from models.hgraph2graph.hgraph.chemprop.utils import load_args, load_checkpoint, load_scalers\n",
    "\n",
    "\n",
    "param_norm = lambda m: math.sqrt(sum([p.norm().item() ** 2 for p in m.parameters()]))\n",
    "grad_norm = lambda m: math.sqrt(sum([p.grad.norm().item() ** 2 for p in m.parameters() if p.grad is not None]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(atom_vocab=<hgraph.vocab.Vocab object at 0x7f6bffccfdf0>, batch_size=2, clip_norm=5.0, depthG=15, depthT=15, diterG=3, diterT=1, dropout=0.0, embed_size=250, epoch=2, generative_model='ckpt/chembl-pretrained/model.ckpt', hidden_size=250, inner_epoch=2, latent_size=32, lr=0.001, max_similarity=0.5, min_similarity=0.1, nsample=10, rnn_type='LSTM', save_dir='ckpt/finetune', seed=7, threshold=0.3, train='data/vadeers/smiles.txt', vocab='data/chembl/vocab.txt')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lg = rdkit.RDLogger.logger()\n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train', default='data/vadeers/smiles.txt')\n",
    "parser.add_argument('--vocab', default='data/chembl/vocab.txt')\n",
    "parser.add_argument('--atom_vocab', default=common_atom_vocab)\n",
    "parser.add_argument('--save_dir', default='ckpt/finetune')\n",
    "parser.add_argument('--generative_model', default='ckpt/chembl-pretrained/model.ckpt')\n",
    "#parser.add_argument('--chemprop_model', required=True)\n",
    "parser.add_argument('--seed', type=int, default=7)\n",
    "\n",
    "parser.add_argument('--rnn_type', type=str, default='LSTM')\n",
    "parser.add_argument('--hidden_size', type=int, default=250)\n",
    "parser.add_argument('--embed_size', type=int, default=250)\n",
    "parser.add_argument('--batch_size', type=int, default=2)\n",
    "parser.add_argument('--latent_size', type=int, default=32)\n",
    "parser.add_argument('--depthT', type=int, default=15)\n",
    "parser.add_argument('--depthG', type=int, default=15)\n",
    "parser.add_argument('--diterT', type=int, default=1)\n",
    "parser.add_argument('--diterG', type=int, default=3)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "parser.add_argument('--clip_norm', type=float, default=5.0)\n",
    "parser.add_argument('--epoch', type=int, default=2)\n",
    "parser.add_argument('--inner_epoch', type=int, default=2)\n",
    "parser.add_argument('--threshold', type=float, default=0.3)\n",
    "parser.add_argument('--min_similarity', type=float, default=0.1)\n",
    "parser.add_argument('--max_similarity', type=float, default=0.5)\n",
    "parser.add_argument('--nsample', type=int, default=10)\n",
    "\n",
    "args = parser.parse_args([])\n",
    "print(args)\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "with open(args.train) as f:\n",
    "    train_smiles = [line.strip(\"\\r\\n \") for line in f]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "vocab = [x.strip(\"\\r\\n \").split() for x in open(args.vocab)]\n",
    "args.vocab = PairVocab(vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "good_smiles = train_smiles\n",
    "train_mol = [Chem.MolFromSmiles(s) for s in train_smiles]\n",
    "train_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 2048) for x in train_mol]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N.N.[Cl-].[Cl-].[Pt+2]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<rdkit.Chem.rdchem.Mol at 0x7f6bffab9940>",
      "image/png": "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\n"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDX = -1\n",
    "print(good_smiles[IDX])\n",
    "train_mol[IDX]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 0\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n",
      "After pruning 1 -> 1\n"
     ]
    }
   ],
   "source": [
    "# Here I want to discard bad molecules\n",
    "\n",
    "smiles_ok = []\n",
    "smiles_invariant = []\n",
    "smiles_invalid = []\n",
    "for smiles in train_smiles:\n",
    "    try:\n",
    "        models.hgraph2graph.hgraph.MoleculeDataset([smiles], args.vocab, args.atom_vocab, 1)\n",
    "        smiles_ok.append(smiles)\n",
    "        smiles_invariant.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles)))\n",
    "    except:\n",
    "        smiles_invalid.append(smiles)\n",
    "\n",
    "good_smiles = smiles_invariant"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "np.savetxt(fname='/home/adam/Projects/vadeers/data/Ready Datasets/Baseline Dataset/smiles_corrected.txt', X=smiles_ok, fmt='%s')\n",
    "np.savetxt(fname='/home/adam/Projects/vadeers/data/Ready Datasets/Baseline Dataset/smiles_invalid.txt', X=smiles_invalid, fmt='%s')\n",
    "np.savetxt(fname='/home/adam/Projects/vadeers/data/Ready Datasets/Baseline Dataset/smiles_corrected_rdkitinvariant.txt', X=smiles_invariant, fmt='%s')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint ckpt/chembl-pretrained/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = HierVAE(args).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "print('Loading from checkpoint ' + args.generative_model)\n",
    "model_state, optimizer_state, _, beta = torch.load(args.generative_model)\n",
    "model.load_state_dict(model_state)\n",
    "optimizer.load_state_dict(optimizer_state)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning 298 -> 289\n",
      "Epoch 0 training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 101/145 [00:41<00:20,  2.19it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoch):\n",
    "    good_smiles = sorted(set(good_smiles))\n",
    "    random.shuffle(good_smiles)\n",
    "    dataset = models.hgraph2graph.hgraph.MoleculeDataset(good_smiles, args.vocab, args.atom_vocab, args.batch_size)\n",
    "\n",
    "    print(f'Epoch {epoch} training...')\n",
    "    for _ in range(args.inner_epoch):\n",
    "        meters = np.zeros(6)\n",
    "        dataloader = DataLoader(dataset, batch_size=1, collate_fn=lambda x:x[0], shuffle=True, num_workers=4)\n",
    "        for batch in tqdm(dataloader):\n",
    "            model.zero_grad()\n",
    "            loss, kl_div, wacc, iacc, tacc, sacc = model(*batch, beta=beta)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "            optimizer.step()\n",
    "            meters = meters + np.array([kl_div, loss.item(), wacc.cpu() * 100, iacc.cpu() * 100, tacc.cpu() * 100, sacc.cpu() * 100])\n",
    "\n",
    "        meters /= len(dataset)\n",
    "        print(\"Beta: %.3f, KL: %.2f, loss: %.3f, Word: %.2f, %.2f, Topo: %.2f, Assm: %.2f, PNorm: %.2f, GNorm: %.2f\" % (beta, meters[0], meters[1], meters[2], meters[3], meters[4], meters[5], param_norm(model), grad_norm(model)))\n",
    "\n",
    "    ckpt = (model.state_dict(), optimizer.state_dict(), epoch, beta)\n",
    "    torch.save(ckpt, os.path.join(args.save_dir, f\"model.ckpt.{epoch}\"))\n",
    "\n",
    "    # Evaluate\n",
    "\n",
    "    print(f'Epoch {epoch} decoding...')\n",
    "    decoded_smiles = []\n",
    "    with torch.no_grad():\n",
    "        for _ in tqdm(range(args.nsample // args.batch_size)):\n",
    "            outputs = model.sample(args.batch_size, greedy=True)\n",
    "            decoded_smiles.extend(outputs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'CCC(C)C(=O)NC(CO)C(C)C'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_smiles[0] # ToDo extract my vobab from it, and add meaning of loss from from issues and make package work"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ToDo's:\n",
    "1. The above loop works with SMILES strings provided as the default data set, but does not work with SMILES provided by Krzyś. This is an open issue in the repo and other people seem to struggle with it as well.\n",
    "\n",
    "#### Questions?\n",
    "\n",
    "1. It seems that fine-tuning uses raw SMILES as input while training from scratch requires a different loader with processed SMILES. Why is that?\n",
    "2. What are the other metrics: `wacc`, `iacc`, `tacc`, `sacc`?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
