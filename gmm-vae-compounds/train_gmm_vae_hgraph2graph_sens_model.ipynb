{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af4577d-c641-441f-8fd4-e56dd6ab8774",
   "metadata": {},
   "source": [
    "# Train sensitivity model with GMM VAE as DVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa53525-0150-462e-aec5-68f14544ba41",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c721898-5dd5-45a0-8a9f-710a0309ec7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%run ./utils/imports.py\n",
    "\n",
    "import utils.utils as utils\n",
    "from models import GMMVAE, SensitivityModelGMMVAE, modules\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/adam/Projects/vadeers/code/gmm-vae-compounds/models/hgraph2graph/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc3e7b-5a56-42f3-ae87-b7d7b87b42d4",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a92253-22d7-42ff-9c9c-6c4bd643d6ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General path\n",
    "dataset_dir = \"/home/adam/Projects/vadeers/data/Ready Datasets/Baseline Dataset/\"\n",
    "\n",
    "# Sensitivity table\n",
    "sensitivity_table = pd.read_csv(os.path.join(dataset_dir, \"sensitivity_table.csv\"))\n",
    "\n",
    "# Cell lines biological data\n",
    "cell_lines_biological_data = pd.read_csv(os.path.join(dataset_dir, \"cell_lines_biological_data_from_deers.csv\"))\n",
    "\n",
    "# SMILES representation\n",
    "drugs_reprs = pd.read_csv(os.path.join(dataset_dir, \"smiles_corrected_rdkitinvariant.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def correct_sensitivity_table(\n",
    "        path_to_sensitivity_table: str,\n",
    "        path_to_sensitivity_table_corrected: str\n",
    "):\n",
    "    \"\"\"Corrects the sensitivity table.\n",
    "    \"\"\"\n",
    "    column_to_extract_smiles_from = 'CanonicalSMILES'\n",
    "\n",
    "    df_corrected = pd.DataFrame([])\n",
    "\n",
    "    df = pd.read_csv(path_to_sensitivity_table)\n",
    "    df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        smiles = row[column_to_extract_smiles_from].values\n",
    "        try:\n",
    "            models.hgraph2graph.hgraph.MoleculeDataset([smiles], args.vocab, args.atom_vocab, 1)\n",
    "            smiles_ok.append(smiles)\n",
    "            smiles_invariant.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles)))\n",
    "        except:\n",
    "            smiles_invalid.append(smiles)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from models.hgraph2graph.hgraph.dataset import MoleculeDataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81c0a652-98cd-40ec-a48c-020c6428afe9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PubChem CID'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/pandas/core/indexes/base.py:3080\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3080\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3081\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:70\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:101\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:4554\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:4562\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'PubChem CID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [17], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Create mappers from IDs to indexes\u001B[39;00m\n\u001B[1;32m      8\u001B[0m cell_line_ID_to_index_mapper \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_ID_to_idx_mapper(cell_lines_biological_data, id_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_line_id\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m drugs_ID_to_smiles_rep_index_mapper \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_ID_to_idx_mapper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdrugs_reprs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mid_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPubChem CID\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m drugs_ID_to_inhib_profiles_index_mapper \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mget_ID_to_idx_mapper(drugs_inhib_profiles, id_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPubChem CID\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# Create main dataset\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/vadeers/code/gmm-vae-compounds/utils/utils.py:193\u001B[0m, in \u001B[0;36mget_ID_to_idx_mapper\u001B[0;34m(df, id_col)\u001B[0m\n\u001B[1;32m    191\u001B[0m     ide \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 193\u001B[0m     ide \u001B[38;5;241m=\u001B[39m \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mid_col\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    194\u001B[0m mapper[\u001B[38;5;28mint\u001B[39m(ide)] \u001B[38;5;241m=\u001B[39m idx\n\u001B[1;32m    195\u001B[0m idx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/pandas/core/series.py:853\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    850\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[0;32m--> 853\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    858\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/pandas/core/series.py:961\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[0;34m(self, label, takeable)\u001B[0m\n\u001B[1;32m    958\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[1;32m    960\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[0;32m--> 961\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    962\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_get_values_for_loc(\u001B[38;5;28mself\u001B[39m, loc, label)\n",
      "File \u001B[0;32m~/miniconda3/envs/hgraph2graph/lib/python3.8/site-packages/pandas/core/indexes/base.py:3082\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3080\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3081\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3082\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tolerance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3085\u001B[0m     tolerance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_tolerance(tolerance, np\u001B[38;5;241m.\u001B[39masarray(key))\n",
      "\u001B[0;31mKeyError\u001B[0m: 'PubChem CID'"
     ]
    }
   ],
   "source": [
    "### Load appropriate data\n",
    "\n",
    "# Load drugs inhibition profiles\n",
    "NO_TRUE_CLUSTER_LABELS = 3\n",
    "drugs_inhib_profiles= pd.read_csv(\"/home/adam/Projects/vadeers/data/Ready Datasets/Baseline Dataset/drugs_inhib_profiles_with_3_guiding_cluster_labels.csv\")\n",
    "\n",
    "# Create mappers from IDs to indexes\n",
    "cell_line_ID_to_index_mapper = utils.get_ID_to_idx_mapper(cell_lines_biological_data, id_col=\"cell_line_id\")\n",
    "drugs_ID_to_smiles_rep_index_mapper = utils.get_ID_to_idx_mapper(drugs_reprs, id_col=\"PubChem CID\")\n",
    "drugs_ID_to_inhib_profiles_index_mapper = utils.get_ID_to_idx_mapper(drugs_inhib_profiles, id_col=\"PubChem CID\")\n",
    "\n",
    "# Create main dataset\n",
    "full_dataset = utils.DatasetThreeTables(sensitivity_table, \n",
    "                                        cell_lines_biological_data.values[:, 1:], \n",
    "                                        drugs_mol2vec_reprs.values[:, 1:], \n",
    "                                        drugs_inhib_profiles.values[:, 1:],\n",
    "                                        cell_line_ID_to_index_mapper, \n",
    "                                        drugs_ID_to_smiles_rep_index_mapper, \n",
    "                                        drugs_ID_to_inhib_profiles_index_mapper,\n",
    "                                        drug_ID_name=\"PubChem CID\", \n",
    "                                        cell_line_ID_name=\"COSMIC_ID\", \n",
    "                                        guiding_data_class_name=\"guiding_data_class\",\n",
    "                                        sensitivity_metric=\"LN_IC50\", \n",
    "                                        drug_ID_index=1, \n",
    "                                        cell_line_ID_index=3, \n",
    "                                        sensitivity_metric_index=4)\n",
    "\n",
    "# Create VAE dataloader\n",
    "VAE_BATCH_SIZE = 8\n",
    "vae_dataset = utils.get_vae_dataset(drugs_mol2vec_reprs, drugs_inhib_profiles)\n",
    "vae_dataloader = DataLoader(vae_dataset, batch_size=VAE_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af638801-267d-4157-871b-1019bc3af248",
   "metadata": {},
   "source": [
    "## Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240932e3-3bf1-4bb5-a2ca-45aee28cbaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sensitivity model with GMM VAE\n",
    "# Input dimensionalities\n",
    "DRUG_INPUT_DIM = 300\n",
    "DRUG_GUIDING_DIM = 294\n",
    "CELL_LINE_INPUT_DIM = 241\n",
    "\n",
    "# Latent spaces dimensionalities\n",
    "DRUG_LATENT_DIM = 10\n",
    "CELL_LINE_LATENT_DIM = 10\n",
    "\n",
    "# NN layers\n",
    "DRUG_ENCODER_LAYERS = (DRUG_INPUT_DIM, 128, 64, DRUG_LATENT_DIM)\n",
    "DRUG_INPUT_DECODER_LAYERS = (DRUG_LATENT_DIM, 64, 128, DRUG_INPUT_DIM)\n",
    "DRUG_GUIDING_DECODER_LAYERS = (DRUG_LATENT_DIM, 64, 128, DRUG_GUIDING_DIM)\n",
    "CELL_LINE_ENCODER_LAYERS = (CELL_LINE_INPUT_DIM, 128, 64, CELL_LINE_LATENT_DIM)\n",
    "CELL_LINE_DECODER_LAYERS = (CELL_LINE_LATENT_DIM, 64, 128, CELL_LINE_INPUT_DIM)\n",
    "\n",
    "# Set number of components in latent GMM\n",
    "NO_GMM_COMPONENTS = NO_TRUE_CLUSTER_LABELS\n",
    "\n",
    "# Transformation to apply before encoders output\n",
    "var_transformation = lambda x: torch.exp(x) ** 0.5\n",
    "\n",
    "# Establish config dict\n",
    "whole_model_config = {\"drug_latent_dim\": DRUG_LATENT_DIM,\n",
    "                        \"cell_line_latent_dim\": CELL_LINE_LATENT_DIM,\n",
    "                        \"no_gmm_components\": NO_GMM_COMPONENTS,\n",
    "                        \"components_std\": 1.,\n",
    "                        \"drug_encoder_layers\": (DRUG_INPUT_DIM, 128, 64, DRUG_LATENT_DIM),\n",
    "                        \"drug_input_decoder_layers\": (DRUG_LATENT_DIM, 64, 128, DRUG_INPUT_DIM),\n",
    "                        \"drug_guiding_decoder_layers\": (DRUG_LATENT_DIM, 64, 128, DRUG_GUIDING_DIM),\n",
    "                        \"cell_line_encoder_layers\": (CELL_LINE_INPUT_DIM, 128, 64, CELL_LINE_LATENT_DIM),\n",
    "                        \"cell_line_decoder_layers\": (CELL_LINE_LATENT_DIM, 64, 128, CELL_LINE_INPUT_DIM),\n",
    "                        \"vae_loss_function_weights\": (1., 1., 1., 1., 0.),\n",
    "                        \"vae_var_transformation\": \"standard\",\n",
    "                        \"optimizer\": \"adam\",\n",
    "                        \"learning_rate\": 0.0005,\n",
    "                        \"aen_reconstruction_weight\": 1.,\n",
    "                        \"sensitivity_prediction_weight\": 1.,\n",
    "                        \"l2_term\": 0.,\n",
    "                        \"pretraining_vae\": False,\n",
    "                        \"batch_size\": 128,\n",
    "                        \"mixed_training\": True,\n",
    "                        \"vae_training_num_epochs\": 100,\n",
    "                        \"vae_training_step_rate\": 1000,\n",
    "                        \"drug_model_learning_rate\": 0.0005,\n",
    "                        \"vae_loader_batch_size\": VAE_BATCH_SIZE, \n",
    "                        \"clip_guiding_rec\": False,\n",
    "                        \"guiding_clip_min\": 0,\n",
    "                        \"guiding_clip_max\": 100}\n",
    "\n",
    "# Establish sensitivity prediction network config\n",
    "sensitivity_prediction_network_config = {\"layers\": (DRUG_LATENT_DIM + CELL_LINE_LATENT_DIM, 512, 256, 128, 1),\n",
    "                                        \"learning_rate\": 0.0005,\n",
    "                                        \"l2_term\": 0,\n",
    "                                        \"dropout_rate1\": 0.5,\n",
    "                                        \"dropout_rate2\": 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22d0c4-11bf-4335-93dc-fd20dedf9d92",
   "metadata": {},
   "source": [
    "## Run the model multiple times with different data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a89b7-eb26-41f3-a093-2f38e0ae43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split seeds\n",
    "SPLIT_SEEDS = [11, 13, 26, 76, 92]\n",
    "\n",
    "# Data split and loaders hyperparameters\n",
    "NUM_TEST_CELL_LINES = 100\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 512\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 200\n",
    "SAVE_CHECKPOINT_EVERY_N_EPOCHS = 10\n",
    "FREEZE_EPOCH = 150\n",
    "AFTER_FREEZE_LR = 0.001\n",
    "STEP_SIZE = 10   # Step for learning rate shrinkage\n",
    "GAMMA = 0.1   # Shrinkage factor for learning rate\n",
    "\n",
    "for exp_run, split_seed in enumerate(SPLIT_SEEDS):\n",
    "    dataset_train, dataset_test, train_cell_lines, test_cell_lines = full_dataset.train_test_split(NUM_TEST_CELL_LINES, seed=split_seed,\n",
    "                                                                                              return_cell_lines=True)\n",
    "    # Create corresponding DataLoaders\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE_TEST)\n",
    "    \n",
    "    pl.utilities.seed.seed_everything(split_seed)\n",
    "    \n",
    "    # Establish drug model\n",
    "    drug_gmm_vae = GMMVAE(whole_model_config[\"drug_encoder_layers\"], whole_model_config[\"drug_input_decoder_layers\"], \n",
    "                          whole_model_config[\"drug_guiding_decoder_layers\"], \n",
    "                          whole_model_config[\"no_gmm_components\"],\n",
    "                          components_std=whole_model_config[\"components_std\"],\n",
    "                          var_transformation=var_transformation, \n",
    "                          learning_rate=whole_model_config[\"drug_model_learning_rate\"],\n",
    "                          loss_function_weights=whole_model_config[\"vae_loss_function_weights\"], \n",
    "                          batch_norm=False, optimizer=\"adam\",\n",
    "                          encoder_dropout_rate=0, decoders_dropout_rate=0,\n",
    "                          clip_guiding_rec=whole_model_config[\"clip_guiding_rec\"],\n",
    "                          guiding_clip_min=whole_model_config[\"guiding_clip_min\"],\n",
    "                          guiding_clip_max=whole_model_config[\"guiding_clip_max\"])\n",
    "    \n",
    "    # Set up trainable componenst stds - comment below line if you want to have fixed isotropic covariance\n",
    "    # matrices in GMM\n",
    "    drug_gmm_vae.stds = nn.Parameter(data=torch.ones(whole_model_config[\"no_gmm_components\"], drug_gmm_vae.latent_dim), requires_grad=True)\n",
    "\n",
    "    # Establish cell line model\n",
    "    cell_line_aen = modules.AutoencoderConfigurable(whole_model_config[\"cell_line_encoder_layers\"], whole_model_config[\"cell_line_decoder_layers\"])\n",
    "\n",
    "    # Three-layer variant\n",
    "    sensitivity_prediction_network = modules.FeedForwardThreeLayersConfigurableDropout(sensitivity_prediction_network_config)\n",
    "    \n",
    "    # Assemble the model\n",
    "    model = SensitivityModelGMMVAE(drug_gmm_vae, cell_line_aen, sensitivity_prediction_network,\n",
    "                                  learning_rate=whole_model_config[\"learning_rate\"],\n",
    "                                  aen_reconstruction_loss_weight=whole_model_config[\"aen_reconstruction_weight\"],\n",
    "                                  sensitivity_loss_weight=whole_model_config[\"sensitivity_prediction_weight\"],\n",
    "                                  vae_dataloader=vae_dataloader) # to na None, wtedy nie ma traning dodatkowego i OK\n",
    "   \n",
    "    # Train the model\n",
    "    # Establish logger\n",
    "    model_name = f\"\"\"GMM_VAE__IP__no_comps={NO_GMM_COMPONENTS}__trained_comp_std\"\"\"\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(rf\"final_runs\\{model_name}\", name=f\"run_{exp_run}_split_seed_{split_seed}\")\n",
    "    \n",
    "    # Establish callbacks\n",
    "    freezing_callback = utils.FreezingCallback(freeze_epoch=FREEZE_EPOCH, new_learning_rate=AFTER_FREEZE_LR, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "    \n",
    "    # Overwrite default checkpoint callback if needed\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_sensitivity_pred_rmse\", every_n_epochs=SAVE_CHECKPOINT_EVERY_N_EPOCHS, every_n_train_steps=None, train_time_interval=None,\n",
    "                                         save_top_k=NUM_EPOCHS // SAVE_CHECKPOINT_EVERY_N_EPOCHS)\n",
    "\n",
    "    # Establish trainer\n",
    "    trainer = pl.Trainer(max_epochs=NUM_EPOCHS, logger=tb_logger, gpus=0, \n",
    "                         callbacks=[freezing_callback, checkpoint_callback])\n",
    "\n",
    "    trainer.fit(model, dataloader_train, dataloader_test)\n",
    "\n",
    "    # Save hyperparams\n",
    "    whole_model_config[\"vae_var_transformation\"] = str(var_transformation)\n",
    "    whole_model_config[\"num_epochs\"] = NUM_EPOCHS\n",
    "    whole_model_config[\"freeze_epoch\"] = FREEZE_EPOCH\n",
    "    whole_model_config[\"after_freeze_lr\"] = AFTER_FREEZE_LR\n",
    "\n",
    "    with open(os.path.join(trainer.log_dir, \"whole_model_config.json\"), \"w\") as f:\n",
    "        json.dump(whole_model_config, f)\n",
    "\n",
    "    with open(os.path.join(trainer.log_dir, \"sensitivity_prediction_network_config.json\"), \"w\") as f:\n",
    "        json.dump(sensitivity_prediction_network_config, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
