{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7af4577d-c641-441f-8fd4-e56dd6ab8774",
   "metadata": {},
   "source": [
    "# Train sensitivity model with GMM VAE as DVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa53525-0150-462e-aec5-68f14544ba41",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c721898-5dd5-45a0-8a9f-710a0309ec7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%run ./utils/imports.py\n",
    "\n",
    "import utils.utils as utils\n",
    "from models import GMMVAE, SensitivityModelGMMVAE, modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cc3e7b-5a56-42f3-ae87-b7d7b87b42d4",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a92253-22d7-42ff-9c9c-6c4bd643d6ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/files\\\\sensitivity_table.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m dataset_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpath/to/files\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Sensitivity table\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m sensitivity_table \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msensitivity_table.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Cell lines biological data\u001B[39;00m\n\u001B[0;32m      8\u001B[0m cell_lines_biological_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(dataset_dir, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_lines_biological_data.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\parsers.py:610\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    605\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    606\u001B[0m     dialect, delimiter, delim_whitespace, engine, sep, defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m    607\u001B[0m )\n\u001B[0;32m    608\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 610\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\parsers.py:462\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    459\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    461\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 462\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\parsers.py:819\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwds:\n\u001B[0;32m    817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 819\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\parsers.py:1050\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1046\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1047\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown engine: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mengine\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (valid options are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmapping\u001B[38;5;241m.\u001B[39mkeys()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1048\u001B[0m     )\n\u001B[0;32m   1049\u001B[0m \u001B[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001B[39;00m\n\u001B[1;32m-> 1050\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\parsers.py:1867\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1864\u001B[0m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124musecols\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39musecols\n\u001B[0;32m   1866\u001B[0m \u001B[38;5;66;03m# open handles\u001B[39;00m\n\u001B[1;32m-> 1867\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open_handles\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1868\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage_options\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmemory_map\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompression\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\parsers.py:1362\u001B[0m, in \u001B[0;36mParserBase._open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_handles\u001B[39m(\u001B[38;5;28mself\u001B[39m, src: FilePathOrBuffer, kwds: Dict[\u001B[38;5;28mstr\u001B[39m, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1359\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m \u001B[38;5;124;03m    Let the readers open IOHanldes after they are done with their potential raises.\u001B[39;00m\n\u001B[0;32m   1361\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1362\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1363\u001B[0m \u001B[43m        \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1364\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1365\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1366\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1367\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1368\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1369\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gmm-vae\\lib\\site-packages\\pandas\\io\\common.py:642\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    640\u001B[0m         errors \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplace\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 642\u001B[0m     handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    643\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    644\u001B[0m \u001B[43m        \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    645\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    646\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    650\u001B[0m     \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    651\u001B[0m     handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'path/to/files\\\\sensitivity_table.csv'"
     ]
    }
   ],
   "source": [
    "# General path\n",
    "dataset_dir = \"path/to/files\"\n",
    "\n",
    "# Sensitivity table\n",
    "sensitivity_table = pd.read_csv(os.path.join(dataset_dir, \"sensitivity_table.csv\"))\n",
    "\n",
    "# Cell lines biological data\n",
    "cell_lines_biological_data = pd.read_csv(os.path.join(dataset_dir, \"cell_lines_biological_data.csv\"))\n",
    "\n",
    "# Drugs SMILES vector representations\n",
    "drugs_mol2vec_reprs = pd.read_csv(os.path.join(dataset_dir, \"drugs_Mol2Vec_reprs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0a652-98cd-40ec-a48c-020c6428afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load appropriate data\n",
    "\n",
    "# Load drugs inhibition profiles\n",
    "NO_TRUE_CLUSTER_LABELS = 3\n",
    "drugs_inhib_profiles= pd.read_csv(\"path/to/files\")\n",
    "\n",
    "# Create mappers from IDs to indexes\n",
    "cell_line_ID_to_index_mapper = utils.get_ID_to_idx_mapper(cell_lines_biological_data, id_col=\"cell_line_id\")\n",
    "drugs_ID_to_smiles_rep_index_mapper = utils.get_ID_to_idx_mapper(drugs_mol2vec_reprs, id_col=\"PubChem CID\")\n",
    "drugs_ID_to_inhib_profiles_index_mapper = utils.get_ID_to_idx_mapper(drugs_inhib_profiles, id_col=\"PubChem CID\")\n",
    "\n",
    "# Create main dataset\n",
    "full_dataset = utils.DatasetThreeTables(sensitivity_table, \n",
    "                                        cell_lines_biological_data.values[:, 1:], \n",
    "                                        drugs_mol2vec_reprs.values[:, 1:], \n",
    "                                        drugs_inhib_profiles.values[:, 1:],\n",
    "                                        cell_line_ID_to_index_mapper, \n",
    "                                        drugs_ID_to_smiles_rep_index_mapper, \n",
    "                                        drugs_ID_to_inhib_profiles_index_mapper,\n",
    "                                        drug_ID_name=\"PubChem CID\", \n",
    "                                        cell_line_ID_name=\"COSMIC_ID\", \n",
    "                                        guiding_data_class_name=\"guiding_data_class\",\n",
    "                                        sensitivity_metric=\"LN_IC50\", \n",
    "                                        drug_ID_index=1, \n",
    "                                        cell_line_ID_index=3, \n",
    "                                        sensitivity_metric_index=4)\n",
    "\n",
    "# Create VAE dataloader\n",
    "VAE_BATCH_SIZE = 8\n",
    "vae_dataset = utils.get_vae_dataset(drugs_mol2vec_reprs, drugs_inhib_profiles)\n",
    "vae_dataloader = DataLoader(vae_dataset, batch_size=VAE_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af638801-267d-4157-871b-1019bc3af248",
   "metadata": {},
   "source": [
    "## Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240932e3-3bf1-4bb5-a2ca-45aee28cbaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sensitivity model with GMM VAE\n",
    "# Input dimensionalities\n",
    "DRUG_INPUT_DIM = 300\n",
    "DRUG_GUIDING_DIM = 294\n",
    "CELL_LINE_INPUT_DIM = 241\n",
    "\n",
    "# Latent spaces dimensionalities\n",
    "DRUG_LATENT_DIM = 10\n",
    "CELL_LINE_LATENT_DIM = 10\n",
    "\n",
    "# NN layers\n",
    "DRUG_ENCODER_LAYERS = (DRUG_INPUT_DIM, 128, 64, DRUG_LATENT_DIM)\n",
    "DRUG_INPUT_DECODER_LAYERS = (DRUG_LATENT_DIM, 64, 128, DRUG_INPUT_DIM)\n",
    "DRUG_GUIDING_DECODER_LAYERS = (DRUG_LATENT_DIM, 64, 128, DRUG_GUIDING_DIM)\n",
    "CELL_LINE_ENCODER_LAYERS = (CELL_LINE_INPUT_DIM, 128, 64, CELL_LINE_LATENT_DIM)\n",
    "CELL_LINE_DECODER_LAYERS = (CELL_LINE_LATENT_DIM, 64, 128, CELL_LINE_INPUT_DIM)\n",
    "\n",
    "# Set number of components in latent GMM\n",
    "NO_GMM_COMPONENTS = NO_TRUE_CLUSTER_LABELS\n",
    "\n",
    "# Transformation to apply before encoders output\n",
    "var_transformation = lambda x: torch.exp(x) ** 0.5\n",
    "\n",
    "# Establish config dict\n",
    "whole_model_config = {\"drug_latent_dim\": DRUG_LATENT_DIM,\n",
    "                        \"cell_line_latent_dim\": CELL_LINE_LATENT_DIM,\n",
    "                        \"no_gmm_components\": NO_GMM_COMPONENTS,\n",
    "                        \"components_std\": 1.,\n",
    "                        \"drug_encoder_layers\": (DRUG_INPUT_DIM, 128, 64, DRUG_LATENT_DIM),\n",
    "                        \"drug_input_decoder_layers\": (DRUG_LATENT_DIM, 64, 128, DRUG_INPUT_DIM),\n",
    "                        \"drug_guiding_decoder_layers\": (DRUG_LATENT_DIM, 64, 128, DRUG_GUIDING_DIM),\n",
    "                        \"cell_line_encoder_layers\": (CELL_LINE_INPUT_DIM, 128, 64, CELL_LINE_LATENT_DIM),\n",
    "                        \"cell_line_decoder_layers\": (CELL_LINE_LATENT_DIM, 64, 128, CELL_LINE_INPUT_DIM),\n",
    "                        \"vae_loss_function_weights\": (1., 1., 1., 1., 0.),\n",
    "                        \"vae_var_transformation\": \"standard\",\n",
    "                        \"optimizer\": \"adam\",\n",
    "                        \"learning_rate\": 0.0005,\n",
    "                        \"aen_reconstruction_weight\": 1.,\n",
    "                        \"sensitivity_prediction_weight\": 1.,\n",
    "                        \"l2_term\": 0.,\n",
    "                        \"pretraining_vae\": False,\n",
    "                        \"batch_size\": 128,\n",
    "                        \"mixed_training\": True,\n",
    "                        \"vae_training_num_epochs\": 100,\n",
    "                        \"vae_training_step_rate\": 1000,\n",
    "                        \"drug_model_learning_rate\": 0.0005,\n",
    "                        \"vae_loader_batch_size\": VAE_BATCH_SIZE, \n",
    "                        \"clip_guiding_rec\": False,\n",
    "                        \"guiding_clip_min\": 0,\n",
    "                        \"guiding_clip_max\": 100}\n",
    "\n",
    "# Establish sensitivity prediction network config\n",
    "sensitivity_prediction_network_config = {\"layers\": (DRUG_LATENT_DIM + CELL_LINE_LATENT_DIM, 512, 256, 128, 1),\n",
    "                                        \"learning_rate\": 0.0005,\n",
    "                                        \"l2_term\": 0,\n",
    "                                        \"dropout_rate1\": 0.5,\n",
    "                                        \"dropout_rate2\": 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22d0c4-11bf-4335-93dc-fd20dedf9d92",
   "metadata": {},
   "source": [
    "## Run the model multiple times with different data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a89b7-eb26-41f3-a093-2f38e0ae43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split seeds\n",
    "SPLIT_SEEDS = [11, 13, 26, 76, 92]\n",
    "\n",
    "# Data split and loaders hyperparameters\n",
    "NUM_TEST_CELL_LINES = 100\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 512\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 200\n",
    "SAVE_CHECKPOINT_EVERY_N_EPOCHS = 10\n",
    "FREEZE_EPOCH = 150\n",
    "AFTER_FREEZE_LR = 0.001\n",
    "STEP_SIZE = 10   # Step for learning rate shrinkage\n",
    "GAMMA = 0.1   # Shrinkage factor for learning rate\n",
    "\n",
    "for exp_run, split_seed in enumerate(SPLIT_SEEDS):\n",
    "    dataset_train, dataset_test, train_cell_lines, test_cell_lines = full_dataset.train_test_split(NUM_TEST_CELL_LINES, seed=split_seed,\n",
    "                                                                                              return_cell_lines=True)\n",
    "    # Create corresponding DataLoaders\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE_TEST)\n",
    "    \n",
    "    pl.utilities.seed.seed_everything(split_seed)\n",
    "    \n",
    "    # Establish drug model\n",
    "    drug_gmm_vae = GMMVAE(whole_model_config[\"drug_encoder_layers\"], whole_model_config[\"drug_input_decoder_layers\"], \n",
    "                          whole_model_config[\"drug_guiding_decoder_layers\"], \n",
    "                          whole_model_config[\"no_gmm_components\"],\n",
    "                          components_std=whole_model_config[\"components_std\"],\n",
    "                          var_transformation=var_transformation, \n",
    "                          learning_rate=whole_model_config[\"drug_model_learning_rate\"],\n",
    "                          loss_function_weights=whole_model_config[\"vae_loss_function_weights\"], \n",
    "                          batch_norm=False, optimizer=\"adam\",\n",
    "                          encoder_dropout_rate=0, decoders_dropout_rate=0,\n",
    "                          clip_guiding_rec=whole_model_config[\"clip_guiding_rec\"],\n",
    "                          guiding_clip_min=whole_model_config[\"guiding_clip_min\"],\n",
    "                          guiding_clip_max=whole_model_config[\"guiding_clip_max\"])\n",
    "    \n",
    "    # Set up trainable componenst stds - comment below line if you want to have fixed isotropic covariance\n",
    "    # matrices in GMM\n",
    "    drug_gmm_vae.stds = nn.Parameter(data=torch.ones(whole_model_config[\"no_gmm_components\"], drug_gmm_vae.latent_dim), requires_grad=True)\n",
    "\n",
    "    # Establish cell line model\n",
    "    cell_line_aen = modules.AutoencoderConfigurable(whole_model_config[\"cell_line_encoder_layers\"], whole_model_config[\"cell_line_decoder_layers\"])\n",
    "\n",
    "    # Three-layer variant\n",
    "    sensitivity_prediction_network = modules.FeedForwardThreeLayersConfigurableDropout(sensitivity_prediction_network_config)\n",
    "    \n",
    "    # Assemble the model\n",
    "    model = SensitivityModelGMMVAE(drug_gmm_vae, cell_line_aen, sensitivity_prediction_network,\n",
    "                                  learning_rate=whole_model_config[\"learning_rate\"],\n",
    "                                  aen_reconstruction_loss_weight=whole_model_config[\"aen_reconstruction_weight\"],\n",
    "                                  sensitivity_loss_weight=whole_model_config[\"sensitivity_prediction_weight\"],\n",
    "                                  vae_dataloader=vae_dataloader) # to na None, wtedy nie ma traning dodatkowego i OK\n",
    "   \n",
    "    # Train the model\n",
    "    # Establish logger\n",
    "    model_name = f\"\"\"GMM_VAE__IP__no_comps={NO_GMM_COMPONENTS}__trained_comp_std\"\"\"\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(rf\"final_runs\\{model_name}\", name=f\"run_{exp_run}_split_seed_{split_seed}\")\n",
    "    \n",
    "    # Establish callbacks\n",
    "    freezing_callback = utils.FreezingCallback(freeze_epoch=FREEZE_EPOCH, new_learning_rate=AFTER_FREEZE_LR, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "    \n",
    "    # Overwrite default checkpoint callback if needed\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_sensitivity_pred_rmse\", every_n_epochs=SAVE_CHECKPOINT_EVERY_N_EPOCHS, every_n_train_steps=None, train_time_interval=None,\n",
    "                                         save_top_k=NUM_EPOCHS // SAVE_CHECKPOINT_EVERY_N_EPOCHS)\n",
    "\n",
    "    # Establish trainer\n",
    "    trainer = pl.Trainer(max_epochs=NUM_EPOCHS, logger=tb_logger, gpus=0, \n",
    "                         callbacks=[freezing_callback, checkpoint_callback])\n",
    "\n",
    "    trainer.fit(model, dataloader_train, dataloader_test)\n",
    "\n",
    "    # Save hyperparams\n",
    "    whole_model_config[\"vae_var_transformation\"] = str(var_transformation)\n",
    "    whole_model_config[\"num_epochs\"] = NUM_EPOCHS\n",
    "    whole_model_config[\"freeze_epoch\"] = FREEZE_EPOCH\n",
    "    whole_model_config[\"after_freeze_lr\"] = AFTER_FREEZE_LR\n",
    "\n",
    "    with open(os.path.join(trainer.log_dir, \"whole_model_config.json\"), \"w\") as f:\n",
    "        json.dump(whole_model_config, f)\n",
    "\n",
    "    with open(os.path.join(trainer.log_dir, \"sensitivity_prediction_network_config.json\"), \"w\") as f:\n",
    "        json.dump(sensitivity_prediction_network_config, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
