{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f5e02fe-9e25-4546-b8dd-9d99c6e8edca",
   "metadata": {},
   "source": [
    "# Train sensitivity model with Vanilla VAE as DVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917fde5-c2d9-45ac-aa7d-41c9f270c838",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5a365-efa2-447e-8730-bbc13cda5f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./utils/imports.py\n",
    "\n",
    "import utils.utils as utils\n",
    "from models import VanillaVAE, SensitivityModelVanillaVAE, modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97329973-719d-4f98-b04a-449e2d56e488",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034124b9-abd1-4368-82b3-4e020fd39ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General path\n",
    "dataset_dir = \"path/to/files\"\n",
    "\n",
    "# Sensitivity table\n",
    "sensitivity_table = pd.read_csv(os.path.join(dataset_dir, \"sensitivity_table.csv\"))\n",
    "\n",
    "# Cell lines biological data\n",
    "cell_lines_biological_data = pd.read_csv(os.path.join(dataset_dir, \"cell_lines_biological_data_from_deers.csv\"))\n",
    "\n",
    "# Drugs SMILES vector representations\n",
    "drugs_mol2vec_reprs = pd.read_csv(os.path.join(dataset_dir, \"drugs_Mol2Vec_reprs.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a24280-9182-42c1-81f0-98aaeaacd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load appropriate data\n",
    "\n",
    "# Load drugs inhibition profiles\n",
    "NO_TRUE_CLUSTER_LABELS = 3\n",
    "drugs_inhib_profiles= pd.read_csv(\"path/to/file\")\n",
    "\n",
    "# Create mappers from IDs to indexes\n",
    "cell_line_ID_to_index_mapper = utils.get_ID_to_idx_mapper(cell_lines_biological_data, id_col=\"cell_line_id\")\n",
    "drugs_ID_to_smiles_rep_index_mapper = utils.get_ID_to_idx_mapper(drugs_mol2vec_reprs, id_col=\"PubChem CID\")\n",
    "drugs_ID_to_inhib_profiles_index_mapper = utils.get_ID_to_idx_mapper(drugs_inhib_profiles, id_col=\"PubChem CID\")\n",
    "\n",
    "# Create main dataset\n",
    "full_dataset = utils.DatasetThreeTables(sensitivity_table, \n",
    "                                        cell_lines_biological_data.values[:, 1:], \n",
    "                                        drugs_mol2vec_reprs.values[:, 1:], \n",
    "                                        drugs_inhib_profiles.values[:, 1:],\n",
    "                                        cell_line_ID_to_index_mapper, \n",
    "                                        drugs_ID_to_smiles_rep_index_mapper, \n",
    "                                        drugs_ID_to_inhib_profiles_index_mapper,\n",
    "                                        drug_ID_name=\"PubChem CID\", \n",
    "                                        cell_line_ID_name=\"COSMIC_ID\", \n",
    "                                        guiding_data_class_name=\"guiding_data_class\",\n",
    "                                        sensitivity_metric=\"LN_IC50\", \n",
    "                                        drug_ID_index=1, \n",
    "                                        cell_line_ID_index=3, \n",
    "                                        sensitivity_metric_index=4)\n",
    "\n",
    "# Create VAE dataloader\n",
    "VAE_BATCH_SIZE = 8\n",
    "vae_dataset = utils.get_vae_dataset(drugs_mol2vec_reprs, drugs_inhib_profiles)\n",
    "vae_dataloader = DataLoader(vae_dataset, batch_size=VAE_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be32cd-9027-43e2-8b29-ccb7325b4d81",
   "metadata": {},
   "source": [
    "## Run the model multiple times with different data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd87594-beed-49eb-ad02-5116a7061e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split seeds\n",
    "SPLIT_SEEDS = [11, 13, 26, 76, 92]\n",
    "\n",
    "# Data split and loaders hyperparameters\n",
    "NUM_TEST_CELL_LINES = 100\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_TEST = 512\n",
    "\n",
    "# Input dimensionalities\n",
    "DRUG_INPUT_DIM = 300\n",
    "DRUG_GUIDING_DIM = 294\n",
    "CELL_LINE_INPUT_DIM = 241\n",
    "\n",
    "# Latent dimensionalities\n",
    "DRUG_LATENT_DIM = 10\n",
    "CELL_LINE_LATENT_DIM = 10\n",
    "\n",
    "## NN layers\n",
    "DRUG_ENCODER_LAYERS = (DRUG_INPUT_DIM, 128, 64, DRUG_LATENT_DIM)\n",
    "DRUG_INPUT_DECODER_LAYERS = (DRUG_LATENT_DIM, 64, 128, DRUG_INPUT_DIM)\n",
    "DRUG_GUIDING_DECODER_LAYERS = (DRUG_LATENT_DIM, 64, 128, DRUG_GUIDING_DIM)\n",
    "CELL_LINE_ENCODER_LAYERS = (CELL_LINE_INPUT_DIM, 128, 64, CELL_LINE_LATENT_DIM)\n",
    "CELL_LINE_DECODER_LAYERS = (CELL_LINE_LATENT_DIM, 64, 128, CELL_LINE_INPUT_DIM)\n",
    "\n",
    "# Establish sensitivity prediction network config\n",
    "sensitivity_prediction_network_config = {\"layers\": (DRUG_LATENT_DIM + CELL_LINE_LATENT_DIM, 512, 256, 128, 1),\n",
    "                                        \"learning_rate\": 0.0005,\n",
    "                                        \"l2_term\": 0,\n",
    "                                        \"dropout_rate1\": 0.5,\n",
    "                                        \"dropout_rate2\": 0.5}\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 200\n",
    "SAVE_CHECKPOINT_EVERY_N_EPOCHS = 10\n",
    "FREEZE_EPOCH = 150\n",
    "AFTER_FREEZE_LR = 0.001\n",
    "STEP_SIZE = 10  # Step for learning rate shrinkage\n",
    "GAMMA = 0.1   # Shrinkage factor for learning rate\n",
    "\n",
    "for exp_run, split_seed in enumerate(SPLIT_SEEDS):\n",
    "    dataset_train, dataset_test, train_cell_lines, test_cell_lines = full_dataset.train_test_split(NUM_TEST_CELL_LINES, seed=split_seed,\n",
    "                                                                                              return_cell_lines=True)\n",
    "    # Create corresponding DataLoaders\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE_TEST)\n",
    "    \n",
    "    pl.utilities.seed.seed_everything(split_seed)\n",
    "    \n",
    "    # Establish drug model\n",
    "    drug_vanilla_vae = VanillaVAE(DRUG_ENCODER_LAYERS, DRUG_INPUT_DECODER_LAYERS, DRUG_GUIDING_DECODER_LAYERS,\n",
    "                     var_transformation=lambda x: torch.exp(x) ** 0.5, learning_rate=0.0005,\n",
    "                     loss_function_weights=(1., 1., 1., 1., 0.0), batch_norm=False, optimizer=\"adam\",\n",
    "                     encoder_dropout_rate=0, decoders_dropout_rate=0, clip_guiding_rec=False\n",
    "                      )\n",
    "\n",
    "    # Establish cell line model\n",
    "    cell_line_aen = modules.AutoencoderConfigurable(CELL_LINE_ENCODER_LAYERS, CELL_LINE_DECODER_LAYERS)\n",
    "    \n",
    "    # Forward network\n",
    "    sensitivity_prediction_network = modules.FeedForwardThreeLayersConfigurableDropout(sensitivity_prediction_network_config)\n",
    "    \n",
    "    # Assemble the model\n",
    "    model = SensitivityModelVanillaVAE(drug_vanilla_vae, cell_line_aen, sensitivity_prediction_network, \n",
    "                                       vae_training_num_epochs=100,\n",
    "                                       vae_training_step_rate=1000,\n",
    "                                       vae_dataloader=vae_dataloader,\n",
    "                                       learning_rate=0.0005)\n",
    "    # Train the model\n",
    "    # Establish logger\n",
    "    model_name = f\"\"\"Vanilla_VAE__IP__dr={sensitivity_prediction_network_config[\"dropout_rate1\"]}_{sensitivity_prediction_network_config[\"dropout_rate2\"]}__gam={GAMMA}\"\"\"\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(rf\"final_runs\\{model_name}\", name=f\"run_{exp_run}_split_seed_{split_seed}\")\n",
    "    \n",
    "    # Establish callbacks\n",
    "    freezing_callback = utils.FreezingCallback(freeze_epoch=FREEZE_EPOCH, new_learning_rate=AFTER_FREEZE_LR, step_size=STEP_SIZE, gamma=GAMMA)\n",
    "    \n",
    "    # Overwrite default checkpoint callback if needed\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_sensitivity_pred_rmse\", every_n_epochs=SAVE_CHECKPOINT_EVERY_N_EPOCHS, every_n_train_steps=None, train_time_interval=None,\n",
    "                                         save_top_k=NUM_EPOCHS // SAVE_CHECKPOINT_EVERY_N_EPOCHS)\n",
    "\n",
    "    # Establish trainer\n",
    "    trainer = pl.Trainer(max_epochs=NUM_EPOCHS, logger=tb_logger, gpus=0, \n",
    "                         callbacks=[freezing_callback, checkpoint_callback])\n",
    "\n",
    "    trainer.fit(model, dataloader_train, dataloader_test)\n",
    "    \n",
    "    # Save hyperparams\n",
    "    with open(os.path.join(trainer.log_dir, \"sensitivity_prediction_network_config.json\"), \"w\") as f:\n",
    "        json.dump(sensitivity_prediction_network_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d5725-3028-41e8-a52b-1123f33518d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac70122-9a12-4501-9485-bcade675bb18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
